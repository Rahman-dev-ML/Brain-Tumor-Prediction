{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcYcDUv6_mC0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "import cv2\n",
        "from skimage import io\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import Sequential\n",
        "from tensorflow.keras import layers, optimizers\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from IPython.display import display\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.preprocessing import StandardScaler, normalize\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "from google.colab import files #library to upload files to colab notebook\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data containing path to Brain MRI and their corresponding mask\n",
        "brain_df = pd.read_csv('data_mask.csv')"
      ],
      "metadata": {
        "id": "C_9Kj1QRAC21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "brain_df.mask_path[1] # Path to the brain MRI image"
      ],
      "metadata": {
        "id": "t44JaK02AIJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "brain_df.image_path[1] # Path to the segmentation mask"
      ],
      "metadata": {
        "id": "y4BkN-mzAKsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "brain_df"
      ],
      "metadata": {
        "id": "7vtGLNjrAM2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "brain_df['mask'].value_counts().index"
      ],
      "metadata": {
        "id": "_o7d6hGKAPEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use plotly to plot interactive bar chart\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure([go.Bar(x = brain_df['mask'].value_counts().index, y = brain_df['mask'].value_counts())])\n",
        "fig.update_traces(marker_color = 'rgb(0,200,0)', marker_line_color = 'rgb(0,255,0)',\n",
        "                  marker_line_width = 7, opacity = 0.6)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "I86BIPWIAQ89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "brain_df.mask_path"
      ],
      "metadata": {
        "id": "ltVb-JkRASeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "brain_df.image_path"
      ],
      "metadata": {
        "id": "vEWYo1zfAUsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(cv2.imread(brain_df.mask_path[623]))"
      ],
      "metadata": {
        "id": "HvlvFZBFAV6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(cv2.imread(brain_df.image_path[623]))"
      ],
      "metadata": {
        "id": "VAUPCstxAYLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2.imread(brain_df.mask_path[623]).max()"
      ],
      "metadata": {
        "id": "Y3NoBXkkAZy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2.imread(brain_df.mask_path[623]).min()"
      ],
      "metadata": {
        "id": "xJvX_65uAcJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic visualizations: Visualize the images (MRI and Mask) in the dataset separately\n",
        "import random\n",
        "fig, axs = plt.subplots(6,2, figsize=(16,32))\n",
        "count = 0\n",
        "for x in range(6):\n",
        "  i = random.randint(0, len(brain_df)) # select a random index\n",
        "  axs[count][0].title.set_text(\"Brain MRI\") # set title\n",
        "  axs[count][0].imshow(cv2.imread(brain_df.image_path[i])) # show MRI\n",
        "  axs[count][1].title.set_text(\"Mask - \" + str(brain_df['mask'][i])) # plot title on the mask (0 or 1)\n",
        "  axs[count][1].imshow(cv2.imread(brain_df.mask_path[i])) # Show corresponding mask\n",
        "  count += 1\n",
        "\n",
        "fig.tight_layout()"
      ],
      "metadata": {
        "id": "wDu8FEr7AdZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "fig, axs = plt.subplots(12, 3, figsize = (20, 50))\n",
        "for i in range(len(brain_df)):\n",
        "  if brain_df['mask'][i] ==1 and count <12:\n",
        "    img = io.imread(brain_df.image_path[i])\n",
        "    axs[count][0].title.set_text('Brain MRI')\n",
        "    axs[count][0].imshow(img)\n",
        "\n",
        "    mask = io.imread(brain_df.mask_path[i])\n",
        "    axs[count][1].title.set_text('Mask')\n",
        "    axs[count][1].imshow(mask, cmap = 'gray')\n",
        "\n",
        "\n",
        "    img[mask == 255] = (255, 0, 0)\n",
        "    axs[count][2].title.set_text('MRI with Mask')\n",
        "    axs[count][2].imshow(img)\n",
        "    count+=1\n",
        "\n",
        "fig.tight_layout()\n"
      ],
      "metadata": {
        "id": "jrysVqwnAfgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the patient id column\n",
        "brain_df_train = brain_df.drop(columns = ['patient_id'])\n",
        "brain_df_train.shape"
      ],
      "metadata": {
        "id": "DsK3NWEvAk6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the data in mask column to string format, to use categorical mode in flow_from_dataframe\n",
        "# You will get this error message if you comment out the following code line:\n",
        "# TypeError: If class_mode=\"categorical\", y_col=\"mask\" column values must be type string, list or tuple.\n",
        "brain_df_train['mask'] = brain_df_train['mask'].apply(lambda x: str(x))"
      ],
      "metadata": {
        "id": "H7psPsSTAwBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "brain_df_train.info()"
      ],
      "metadata": {
        "id": "hlPV1ILUAxpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data into train and test data\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(brain_df_train, test_size = 0.15)\n",
        "# create a image generator\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Create a data generator which scales the data from 0 to 1 and makes validation split of 0.15\n",
        "datagen = ImageDataGenerator(rescale=1./255., validation_split = 0.15)\n",
        "train_generator=datagen.flow_from_dataframe(\n",
        "dataframe=train,\n",
        "directory= './',\n",
        "x_col='image_path',\n",
        "y_col='mask',\n",
        "subset=\"training\",\n",
        "batch_size=16,\n",
        "shuffle=True,\n",
        "class_mode=\"categorical\",\n",
        "target_size=(256,256))\n",
        "\n",
        "\n",
        "valid_generator=datagen.flow_from_dataframe(\n",
        "dataframe=train,\n",
        "directory= './',\n",
        "x_col='image_path',\n",
        "y_col='mask',\n",
        "subset=\"validation\",\n",
        "batch_size=16,\n",
        "shuffle=True,\n",
        "class_mode=\"categorical\",\n",
        "target_size=(256,256))\n",
        "\n",
        "# Create a data generator for test images\n",
        "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
        "\n",
        "test_generator=test_datagen.flow_from_dataframe(\n",
        "dataframe=test,\n",
        "directory= './',\n",
        "x_col='image_path',\n",
        "y_col='mask',\n",
        "batch_size=16,\n",
        "shuffle=False,\n",
        "class_mode='categorical',\n",
        "target_size=(256,256))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qLtixluAAz9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the ResNet50 base model For prediction\n",
        "basemodel = ResNet50(weights = 'imagenet', include_top = False, input_tensor = Input(shape=(256, 256, 3)))\n",
        "basemodel.summary()"
      ],
      "metadata": {
        "id": "I8eqtIfGA7L-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# freeze the model weights\n",
        "\n",
        "for layer in basemodel.layers:\n",
        "  layers.trainable = False"
      ],
      "metadata": {
        "id": "LhqnrxmNA_tQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add classification head to the base model\n",
        "\n",
        "headmodel = basemodel.output\n",
        "headmodel = AveragePooling2D(pool_size = (4,4))(headmodel)\n",
        "headmodel = Flatten(name= 'flatten')(headmodel)\n",
        "headmodel = Dense(256, activation = \"relu\")(headmodel)\n",
        "headmodel = Dropout(0.3)(headmodel)#\n",
        "headmodel = Dense(256, activation = \"relu\")(headmodel)\n",
        "headmodel = Dropout(0.3)(headmodel)\n",
        "#headmodel = Dense(256, activation = \"relu\")(headmodel)\n",
        "#headmodel = Dropout(0.3)(headmodel)\n",
        "headmodel = Dense(2, activation = 'softmax')(headmodel)\n",
        "\n",
        "model = Model(inputs = basemodel.input, outputs = headmodel)"
      ],
      "metadata": {
        "id": "4OCD0yj5BB-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "y5M0AydsBDTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics= [\"accuracy\"])\n",
        "# use early stopping to exit training if validation loss is not decreasing even after certain epochs (patience)\n",
        "earlystopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
        "\n",
        "# save the best model with least validation loss\n",
        "checkpointer = ModelCheckpoint(filepath=\"classifier-resnet-weights.hdf5\", verbose=1, save_best_only=True)\n",
        "history = model.fit(train_generator, steps_per_epoch= train_generator.n // 16, epochs = 1, validation_data= valid_generator, validation_steps= valid_generator.n // 16, callbacks=[checkpointer, earlystopping])\n"
      ],
      "metadata": {
        "id": "5Q3YyS8gBE58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model architecture to json file for future use\n",
        "\n",
        "model_json = model.to_json()\n",
        "with open(\"classifier-resnet-model.json\",\"w\") as json_file:\n",
        "  json_file.write(model_json)"
      ],
      "metadata": {
        "id": "BunmkqB8BKmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pretrained model (instead of training the model for 1+ hours)\n",
        "with open('resnet-50-MRI.json', 'r') as json_file:\n",
        "    json_savedModel= json_file.read()\n",
        "# load the model\n",
        "model = tf.keras.models.model_from_json(json_savedModel)\n",
        "model.load_weights('weights.hdf5')\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics= [\"accuracy\"])"
      ],
      "metadata": {
        "id": "gsduwecWBMd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make prediction\n",
        "\n",
        "test_predict = model.predict(test_generator, steps = test_generator.n // 16, verbose =1)"
      ],
      "metadata": {
        "id": "0jzIoYzQBPDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predict"
      ],
      "metadata": {
        "id": "eP2a_2ESBQps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain the predicted class from the model prediction\n",
        "predict = []\n",
        "\n",
        "for i in test_predict:\n",
        "  predict.append(str(np.argmax(i)))\n",
        "\n",
        "predict = np.asarray(predict)\n",
        "predict"
      ],
      "metadata": {
        "id": "3NzLASmZBUbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain the accuracy of the model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy = accuracy_score(original, predict)\n",
        "accuracy\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "report = classification_report(original, predict, labels = [0,1])\n",
        "print(report)"
      ],
      "metadata": {
        "id": "FDmiqpVjBWg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RESUNIT MODEL\n",
        "# Get the dataframe containing MRIs which have masks associated with them.\n",
        "brain_df_mask = brain_df[brain_df['mask'] == 1]\n",
        "brain_df_mask.shape\n",
        "# split the data into train and test data\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val = train_test_split(brain_df_mask, test_size=0.15)\n",
        "X_test, X_val = train_test_split(X_val, test_size=0.5)\n",
        "\n",
        "# create separate list for imageId, classId to pass into the generator\n",
        "\n",
        "train_ids = list(X_train.image_path)\n",
        "train_mask = list(X_train.mask_path)\n",
        "\n",
        "val_ids = list(X_val.image_path)\n",
        "val_mask= list(X_val.mask_path)\n",
        "\n",
        "# Utilities file contains the code for custom loss function and custom data generator\n",
        "from utilities import DataGenerator\n",
        "\n",
        "# create image generators\n",
        "\n",
        "training_generator = DataGenerator(train_ids,train_mask)\n",
        "validation_generator = DataGenerator(val_ids,val_mask)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-p_VXZYhBdjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resblock(X, f):\n",
        "\n",
        "\n",
        "  # make a copy of input\n",
        "  X_copy = X\n",
        "\n",
        "  # main path\n",
        "  # Read more about he_normal: https://medium.com/@prateekvishnu/xavier-and-he-normal-he-et-al-initialization-8e3d7a087528\n",
        "\n",
        "  X = Conv2D(f, kernel_size = (1,1) ,strides = (1,1),kernel_initializer ='he_normal')(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation('relu')(X)\n",
        "\n",
        "  X = Conv2D(f, kernel_size = (3,3), strides =(1,1), padding = 'same', kernel_initializer ='he_normal')(X)\n",
        "  X = BatchNormalization()(X)\n",
        "\n",
        "  # Short path\n",
        "  # Read more here: https://towardsdatascience.com/understanding-and-coding-a-resnet-in-keras-446d7ff84d33\n",
        "\n",
        "  X_copy = Conv2D(f, kernel_size = (1,1), strides =(1,1), kernel_initializer ='he_normal')(X_copy)\n",
        "  X_copy = BatchNormalization()(X_copy)\n",
        "\n",
        "  # Adding the output from main path and short path together\n",
        "\n",
        "  X = Add()([X,X_copy])\n",
        "  X = Activation('relu')(X)\n",
        "\n",
        "  return X\n",
        ""
      ],
      "metadata": {
        "id": "JU6iiuz7CrNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to upscale and concatenate the values passsed\n",
        "def upsample_concat(x, skip):\n",
        "  x = UpSampling2D((2,2))(x)\n",
        "  merge = Concatenate()([x, skip])\n",
        "\n",
        "  return merge\n",
        "input_shape = (256,256,3)\n",
        "\n",
        "# Input tensor shape\n",
        "X_input = Input(input_shape)\n",
        "\n",
        "# Stage 1\n",
        "conv1_in = Conv2D(16,3,activation= 'relu', padding = 'same', kernel_initializer ='he_normal')(X_input)\n",
        "conv1_in = BatchNormalization()(conv1_in)\n",
        "conv1_in = Conv2D(16,3,activation= 'relu', padding = 'same', kernel_initializer ='he_normal')(conv1_in)\n",
        "conv1_in = BatchNormalization()(conv1_in)\n",
        "pool_1 = MaxPool2D(pool_size = (2,2))(conv1_in)\n",
        "\n",
        "# Stage 2\n",
        "conv2_in = resblock(pool_1, 32)\n",
        "pool_2 = MaxPool2D(pool_size = (2,2))(conv2_in)\n",
        "\n",
        "# Stage 3\n",
        "conv3_in = resblock(pool_2, 64)\n",
        "pool_3 = MaxPool2D(pool_size = (2,2))(conv3_in)\n",
        "\n",
        "# Stage 4\n",
        "conv4_in = resblock(pool_3, 128)\n",
        "pool_4 = MaxPool2D(pool_size = (2,2))(conv4_in)\n",
        "\n",
        "# Stage 5 (Bottle Neck)\n",
        "conv5_in = resblock(pool_4, 256)\n",
        "\n",
        "# Upscale stage 1\n",
        "up_1 = upsample_concat(conv5_in, conv4_in)\n",
        "up_1 = resblock(up_1, 128)\n",
        "\n",
        "# Upscale stage 2\n",
        "up_2 = upsample_concat(up_1, conv3_in)\n",
        "up_2 = resblock(up_2, 64)\n",
        "\n",
        "# Upscale stage 3\n",
        "up_3 = upsample_concat(up_2, conv2_in)\n",
        "up_3 = resblock(up_3, 32)\n",
        "\n",
        "# Upscale stage 4\n",
        "up_4 = upsample_concat(up_3, conv1_in)\n",
        "up_4 = resblock(up_4, 16)\n",
        "\n",
        "# Final Output\n",
        "output = Conv2D(1, (1,1), padding = \"same\", activation = \"sigmoid\")(up_4)\n",
        "\n",
        "model_seg = Model(inputs = X_input, outputs = output )\n"
      ],
      "metadata": {
        "id": "1VZf3kcfCwP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_seg.summary()"
      ],
      "metadata": {
        "id": "6soeV7SrC0AX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TRANINIG OF RESUNT MODEL\n",
        "# Utilities file contains the code for custom loss function and custom data generator\n",
        "\n",
        "from utilities import focal_tversky, tversky_loss, tversky\n",
        "\n",
        "# Compile the model\n",
        "adam = tf.keras.optimizers.Adam(lr = 0.05, epsilon = 0.1)\n",
        "model_seg.compile(optimizer = adam, loss = focal_tversky, metrics = [tversky])\n",
        "\n",
        "# use early stopping to exit training if validation loss is not decreasing even after certain epochs (patience)\n",
        "earlystopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
        "\n",
        "# save the best model with lower validation loss\n",
        "checkpointer = ModelCheckpoint(filepath=\"ResUNet-weights.hdf5\", verbose=1, save_best_only=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "IsLEztDoC0Xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_seg.fit(training_generator, epochs = 1, validation_data = validation_generator, callbacks = [checkpointer, earlystopping])\n"
      ],
      "metadata": {
        "id": "hbGD2r9wC0fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model architecture to json file for future use\n",
        "\n",
        "model_json = model_seg.to_json()\n",
        "with open(\"ResUNet-model.json\",\"w\") as json_file:\n",
        "  json_file.write(model_json)"
      ],
      "metadata": {
        "id": "tqARk7u6DAT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from utilities import focal_tversky, tversky_loss, tversky\n",
        "\n",
        "with open('ResUNet-MRI.json', 'r') as json_file:\n",
        "    json_savedModel= json_file.read()\n",
        "\n",
        "# load the model architecture\n",
        "model_seg = tf.keras.models.model_from_json(json_savedModel)\n",
        "model_seg.load_weights('weights_seg.hdf5')\n",
        "adam = tf.keras.optimizers.Adam(lr = 0.05, epsilon = 0.1)\n",
        "model_seg.compile(optimizer = adam, loss = focal_tversky, metrics = [tversky])"
      ],
      "metadata": {
        "id": "UIK9aA0DDB43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilities file contains the code for custom loss function and custom data generator\n",
        "from utilities import prediction\n",
        "\n",
        "# making prediction\n",
        "image_id, mask, has_mask = prediction(test, model, model_seg)"
      ],
      "metadata": {
        "id": "UM74aXFTDDUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a dataframe for the result\n",
        "df_pred = pd.DataFrame({'image_path': image_id,'predicted_mask': mask,'has_mask': has_mask})\n",
        "df_pred"
      ],
      "metadata": {
        "id": "a0A4at89DEoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the dataframe containing predicted results with the original test data.\n",
        "df_pred = test.merge(df_pred, on = 'image_path')\n",
        "df_pred.head()"
      ],
      "metadata": {
        "id": "qEzKfSqeDGO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "fig, axs = plt.subplots(10, 5, figsize=(30, 50))\n",
        "for i in range(len(df_pred)):\n",
        "  if df_pred['has_mask'][i] == 1 and count < 10:\n",
        "    # read the images and convert them to RGB format\n",
        "    img = io.imread(df_pred.image_path[i])\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    axs[count][0].title.set_text(\"Brain MRI\")\n",
        "    axs[count][0].imshow(img)\n",
        "\n",
        "    # Obtain the mask for the image\n",
        "    mask = io.imread(df_pred.mask_path[i])\n",
        "    axs[count][1].title.set_text(\"Original Mask\")\n",
        "    axs[count][1].imshow(mask)\n",
        "\n",
        "    # Obtain the predicted mask for the image\n",
        "    predicted_mask = np.asarray(df_pred.predicted_mask[i])[0].squeeze().round()\n",
        "    axs[count][2].title.set_text(\"AI Predicted Mask\")\n",
        "    axs[count][2].imshow(predicted_mask)\n",
        "\n",
        "    # Apply the mask to the image 'mask==255'\n",
        "    img[mask == 255] = (255, 0, 0)\n",
        "    axs[count][3].title.set_text(\"MRI with Original Mask (Ground Truth)\")\n",
        "    axs[count][3].imshow(img)\n",
        "\n",
        "    img_ = io.imread(df_pred.image_path[i])\n",
        "    img_ = cv2.cvtColor(img_, cv2.COLOR_BGR2RGB)\n",
        "    img_[predicted_mask == 1] = (0, 255, 0)\n",
        "    axs[count][4].title.set_text(\"MRI with AI Predicted Mask\")\n",
        "    axs[count][4].imshow(img_)\n",
        "    count += 1\n",
        "\n",
        "fig.tight_layout()"
      ],
      "metadata": {
        "id": "EWgaClSEDJ2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "roqlG4pdDLXT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}